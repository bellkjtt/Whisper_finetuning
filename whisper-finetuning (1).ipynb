{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M-63RTbwl8PR"
   },
   "source": [
    "# OpenAI Whisper Fine-tuning for Korean ASR with HuggingFace Transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h-HN1eiHllNl"
   },
   "source": [
    "본격적인 작업에 앞서, Colab을 사용하여 본 작업을 수행한다면 데이터의 전처리 작업까지는 CPU를 활용하는 것을 권장한다. 데이터 전처리 후 Huggingface에 전처리된 데이터셋을 업로드하고, 그 후에 런타임 유형을 GPU로 변환하여 전처리된 데이터셋을 로드, 모델의 학습을 수행한다면 Colab 컴퓨팅 자원의 소모를 방지할 수 있을 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kxQB4IEFz5qo"
   },
   "source": [
    "### Prepare Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "wGDyAhq7zoc0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting git+https://github.com/huggingface/transformers\n",
      "  Cloning https://github.com/huggingface/transformers to /tmp/pip-req-build-pwatqag7\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers /tmp/pip-req-build-pwatqag7\n",
      "  Resolved https://github.com/huggingface/transformers to commit 570c89625b329a2d33ecbfb972a9aae015535471\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from transformers==4.46.0.dev0) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.11/site-packages (from transformers==4.46.0.dev0) (0.25.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.11/site-packages (from transformers==4.46.0.dev0) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from transformers==4.46.0.dev0) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.11/site-packages (from transformers==4.46.0.dev0) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.11/site-packages (from transformers==4.46.0.dev0) (2024.9.11)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from transformers==4.46.0.dev0) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.11/site-packages (from transformers==4.46.0.dev0) (0.20.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.11/site-packages (from transformers==4.46.0.dev0) (0.4.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.11/site-packages (from transformers==4.46.0.dev0) (4.66.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.46.0.dev0) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.46.0.dev0) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->transformers==4.46.0.dev0) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->transformers==4.46.0.dev0) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests->transformers==4.46.0.dev0) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests->transformers==4.46.0.dev0) (2024.7.4)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: jiwer in /opt/conda/lib/python3.11/site-packages (3.0.4)\n",
      "Requirement already satisfied: click<9.0.0,>=8.1.3 in /opt/conda/lib/python3.11/site-packages (from jiwer) (8.1.7)\n",
      "Requirement already satisfied: rapidfuzz<4,>=3 in /opt/conda/lib/python3.11/site-packages (from jiwer) (3.10.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: accelerate in /opt/conda/lib/python3.11/site-packages (0.34.2)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in /opt/conda/lib/python3.11/site-packages (from accelerate) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from accelerate) (24.1)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.11/site-packages (from accelerate) (5.9.0)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.11/site-packages (from accelerate) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.11/site-packages (from accelerate) (2.3.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in /opt/conda/lib/python3.11/site-packages (from accelerate) (0.25.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/conda/lib/python3.11/site-packages (from accelerate) (0.4.5)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.21.0->accelerate) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.21.0->accelerate) (2024.6.1)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.21.0->accelerate) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.21.0->accelerate) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.21.0->accelerate) (4.11.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (3.1.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /opt/conda/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /opt/conda/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: triton==2.3.1 in /opt/conda/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (2.3.1)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate) (12.6.68)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2024.7.4)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.11/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: transformers[torch] in /opt/conda/lib/python3.11/site-packages (4.46.0.dev0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from transformers[torch]) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.11/site-packages (from transformers[torch]) (0.25.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.11/site-packages (from transformers[torch]) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from transformers[torch]) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.11/site-packages (from transformers[torch]) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.11/site-packages (from transformers[torch]) (2024.9.11)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from transformers[torch]) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.11/site-packages (from transformers[torch]) (0.20.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.11/site-packages (from transformers[torch]) (0.4.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.11/site-packages (from transformers[torch]) (4.66.4)\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.11/site-packages (from transformers[torch]) (2.3.1)\n",
      "Requirement already satisfied: accelerate>=0.26.0 in /opt/conda/lib/python3.11/site-packages (from transformers[torch]) (0.34.2)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.11/site-packages (from accelerate>=0.26.0->transformers[torch]) (5.9.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers[torch]) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers[torch]) (4.11.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.11/site-packages (from torch->transformers[torch]) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch->transformers[torch]) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch->transformers[torch]) (3.1.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch->transformers[torch]) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch->transformers[torch]) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch->transformers[torch]) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /opt/conda/lib/python3.11/site-packages (from torch->transformers[torch]) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.11/site-packages (from torch->transformers[torch]) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.11/site-packages (from torch->transformers[torch]) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.11/site-packages (from torch->transformers[torch]) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.11/site-packages (from torch->transformers[torch]) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.11/site-packages (from torch->transformers[torch]) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /opt/conda/lib/python3.11/site-packages (from torch->transformers[torch]) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch->transformers[torch]) (12.1.105)\n",
      "Requirement already satisfied: triton==2.3.1 in /opt/conda/lib/python3.11/site-packages (from torch->transformers[torch]) (2.3.1)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->transformers[torch]) (12.6.68)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->transformers[torch]) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->transformers[torch]) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests->transformers[torch]) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests->transformers[torch]) (2024.7.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch->transformers[torch]) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.11/site-packages (from sympy->torch->transformers[torch]) (1.3.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: wandb in /opt/conda/lib/python3.11/site-packages (0.18.2)\n",
      "Requirement already satisfied: click!=8.0.0,>=7.1 in /opt/conda/lib/python3.11/site-packages (from wandb) (8.1.7)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.11/site-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /opt/conda/lib/python3.11/site-packages (from wandb) (3.1.43)\n",
      "Requirement already satisfied: platformdirs in /opt/conda/lib/python3.11/site-packages (from wandb) (3.10.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /opt/conda/lib/python3.11/site-packages (from wandb) (5.28.2)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.11/site-packages (from wandb) (5.9.0)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.11/site-packages (from wandb) (6.0.1)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /opt/conda/lib/python3.11/site-packages (from wandb) (2.32.3)\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in /opt/conda/lib/python3.11/site-packages (from wandb) (2.14.0)\n",
      "Requirement already satisfied: setproctitle in /opt/conda/lib/python3.11/site-packages (from wandb) (1.3.3)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.11/site-packages (from wandb) (69.5.1)\n",
      "Requirement already satisfied: six>=1.4.0 in /opt/conda/lib/python3.11/site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.11/site-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests<3,>=2.0.0->wandb) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests<3,>=2.0.0->wandb) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests<3,>=2.0.0->wandb) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests<3,>=2.0.0->wandb) (2024.7.4)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.11/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: tensorboardX in /opt/conda/lib/python3.11/site-packages (2.6.2.2)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.11/site-packages (from tensorboardX) (1.26.4)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.11/site-packages (from tensorboardX) (24.1)\n",
      "Requirement already satisfied: protobuf>=3.20 in /opt/conda/lib/python3.11/site-packages (from tensorboardX) (5.28.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install datasets>=2.6.1\n",
    "!pip install git+https://github.com/huggingface/transformers\n",
    "!pip install evaluate>=0.30\n",
    "!pip install jiwer\n",
    "!pip install accelerate -U\n",
    "!pip install transformers[torch]\n",
    "!pip install wandb\n",
    "!pip install tensorboardX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: fineGrained).\n",
      "Your token has been saved to /root/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "# from kaggle_secrets import UserSecretsClient\n",
    "from huggingface_hub import login\n",
    "\n",
    "# # Kaggle User Secrets에서 Hugging Face 토큰 가져오기\n",
    "# user_secrets = UserSecretsClient()\n",
    "# huggingface_token = user_secrets.get_secret(\"HUGGINGFACE_KEY\")\n",
    "huggingface_token = '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'\n",
    "# Hugging Face에 로그인\n",
    "login(huggingface_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pu1C3VJC0i6N"
   },
   "source": [
    "### Prepare Feature Extractor and Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ldqeYHRg1Lnq"
   },
   "source": [
    "음성 인식 Pipeline은 다음과 같이 세 가지 구성으로 나눌 수 있다.\n",
    "1. 오디오 raw data에 대하여 pre-process를 진행할 feature extractor\n",
    "2. sequence-to-sequence 매핑을 수행할 model\n",
    "3. model의 output을 text 포맷으로 후처리할 tokenizer\n",
    "\n",
    "HuggingFace의 Transformers는 Whisper의 모델과 함께 이와 연관된 WhisperFeatureExtractor와 WhisperTokenizer를 함께 제공하고 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kXjUUiyt2StH"
   },
   "source": [
    "#### Load WhisperFeatureExtractor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OOikJDfl2dEz"
   },
   "source": [
    "발화는 시간에 따라 변화하는 1차원 배열로 표현된다. 각 시계열별로 입력된 배열의 값은 그 순간의 신호가 갖는 진폭이다. 그 진폭의 정보만으로, 우리는 음성 데이터의 주파수 스펙트럼을 재구성하고 모든 음향적 특징을 복원할 수 있다.\n",
    "\n",
    "발화는 연속적이므로, 진폭의 값은 무한하다. 그리고 이는 유한한 배열을 기대하는 컴퓨터 장치에 문제를 야기한다. 따라서, 우리는 고정된 시간 간격에 따라 신호에서 값을 샘플링하여 우리의 음성 신호를 분할한다. 오디오를 샘플링하는 간격은 sampling rate로 알려져 있으며, 이는 일반적으로 '샘플/초' 또는 헤르츠(Hz) 단위로 측정된다. 높은 sample rate로 샘플링하는 것은 연속적인 발화 신호에 대하여 더 나은 접근을 가능케 하지만, 초당 더 많은 값을 저장하도록 요구하기도 한다.\n",
    "\n",
    "우리가 가진 오디오 데이터의 sampling rate를 우리가 사용할 모델이 기대하는 sampling rate와 일치시키는 것은 매우 중요한데, 서로 다른 sampling rate의 오디오 신호는 매우 다른 분포를 보이기 때문이다. 오디오 신호는 적절한 sampling rate로 처리되어야만 한다. 그렇지 않으면 예상치 못한 결과를 야기할 수 있다. 예를 들어, 16kHz로 샘플링된 오디오 샘플을 8kHz의 sampling rate로 들으면 해당 오디오의 속도가 절반으로 들릴 것이다. 동일한 방식으로, 잘못된 sampling rate의 오디오 데이터를 ASR 모델에 넘길 경우 모델이 불안정해질 수 있다. Whisper Feature Extractor는 16kHz의 오디오 데이터를 요구하며, 우리는 우리가 가진 오디오 데이터를 이에 맞추어야 한다.\n",
    "\n",
    "Whisper Feature Extractor는 두 가지 동작을 수행한다. 먼저 오디오 샘플에 대하여 padding 및 trucating을 진행하여 모든 샘플들의 길이를 30초로 맞춘다. 30초보다 짧은 샘플은 0으로 채워 30초로 맞추고(음성 신호에서 0은 신호 없음 혹은 침묵을 의미한다), 30초보다 긴 샘플들은 30초로 잘라낸다. 이처럼 인풋 단계에서 각 배치의 모든 요소들이 최대 길이로 채워지거나 잘라지기 때문에, 우리는 Whisper 모델에 데이터를 전달할 때 Attention mask를 필요로 하지 않는다. Whisper 모델은 이 부분에서 독특한데, 대부분의 오디오 모델은 sequence가 패딩된 위치와 self-attention 메커니즘이 어느 부분을 무시해야 하는지에 대한 상세 정보를 제공하는 attention mask를 필요로 한다. 그러나 Whisper는 이러한 attention mask 없이 발화 신호로부터 무시해야 할 인풋을 직접 추론하도록 학습되었다.\n",
    "\n",
    "Whisper Feature Extractor의 두 번째 동작은 피댕된 오디오 배열을 log-Mel 스펙트럼으로 변환하는 것이다. 이 스펙트럼은 푸리에 변환과 같이 주파수 신호를 시각적으로 나타낸 것이다.Whisper 모델의 인풋으로 주어져야 하는 것이 바로 이 log-Mel 스펙트럼이다.\n",
    "\n",
    "Transformer의 Whisper Feature Extractor는 패딩과 스펙트로그램 변환을 단 한 줄의 코드로 수행할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "c0415d722c5f4315bf0f5a20c3adfe31",
      "2482321188ca4d7ea7d0aa05a55c6a17",
      "c704283085e843b1a60656aa93a3dc09",
      "89208f995baf43acb49a90411ceb50d2",
      "057be99b849b4430b0b6ba9b5a78ffd0",
      "579a883a320f41a7804aa962b5717184",
      "8a7488b190d6481ab5da60b8dd1fa99f",
      "ee23f65322c5441a8bc3d119e2e59bfc",
      "2de632dca3b54dd3804b8780ad47ae3c",
      "8c98f4c838e34fe3b1fee4d0224ec777",
      "a4d2300d505b4195bc453b69e6d68a7c"
     ]
    },
    "id": "5MOWGniR-eIl",
    "outputId": "35384bdc-3ee2-48ed-cf9d-598b4562a725"
   },
   "outputs": [],
   "source": [
    "from transformers import WhisperFeatureExtractor\n",
    "# 파인튜닝을 진행하고자 하는 모델의 feature extractor를 로드\n",
    "model_id = \"openai/whisper-large-v3\"\n",
    "feature_extractor = WhisperFeatureExtractor.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M7q8ht02_frC"
   },
   "source": [
    "#### Load WhisperTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2LIO59vx_iby"
   },
   "source": [
    "Whisper 모델의 아웃풋은 vocabulary item들의 단어 중 예측된 텍스트를 나타내는 index값이다. Tokenizer는 이러한 텍스트 토큰 시퀀스와 실제 텍스트 문자열을 매핑해준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "r75NnnX8AlmR"
   },
   "outputs": [],
   "source": [
    "from transformers import WhisperTokenizer\n",
    "# 파인튜닝을 진행하고자 하는 모델의 tokenizer를 로드\n",
    "tokenizer = WhisperTokenizer.from_pretrained(model_id, language=\"Korean\", task=\"transcribe\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ngr5ehEEE7Xr"
   },
   "source": [
    "WhisperTokenizer는 인코딩 과정에서 'Special token'들을 부여한다. 여기에는 문장의 시작과 끝을 나타내는 토큰(전사의 시작과 끝을 나타내는 토큰을 포함한다), 언어를 나타내는 토큰, 태스크(전사, 번역 등)를 나타내는 토큰 등이 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TrDi4NAgE7dK",
    "outputId": "cd76d8d2-7502-4520-8d5f-1fc3f1a46195"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:                 저는 서울중앙지검 지능범죄수사팀 최인호 검사입니다.\n",
      "Decoded w/ special:    <|startoftranscript|><|ko|><|transcribe|><|notimestamps|>저는 서울중앙지검 지능범죄수사팀 최인호 검사입니다.<|endoftext|>\n",
      "Decoded w/out special: 저는 서울중앙지검 지능범죄수사팀 최인호 검사입니다.\n",
      "Are equal:             True\n"
     ]
    }
   ],
   "source": [
    "input_str = \"저는 서울중앙지검 지능범죄수사팀 최인호 검사입니다.\"\n",
    "labels = tokenizer(input_str).input_ids\n",
    "decoded_with_special = tokenizer.decode(labels, skip_special_tokens=False)\n",
    "decoded_str = tokenizer.decode(labels, skip_special_tokens=True)\n",
    "\n",
    "print(f\"Input:                 {input_str}\")\n",
    "print(f\"Decoded w/ special:    {decoded_with_special}\")\n",
    "print(f\"Decoded w/out special: {decoded_str}\")\n",
    "print(f\"Are equal:             {input_str == decoded_str}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|endoftext|>'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.pad_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|endoftext|>'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BzE75HKSF8Fj"
   },
   "source": [
    "#### Combine To Create a WhisperProcessor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I3ohliyiGHAa"
   },
   "source": [
    "Feature Extactor와 Tokenizer를 간편히 사용하기 위해, 두 모듈을 WhisperProcessor 클래스 하나로 묶을 수 있다. Processor는 Feature Extactor와 Tokenizer를 상속하며, 오디오 인풋의 입력과 모델의 예측에 사용할 수 있다. 이로써 우리는 훈련 과정에서 Processor와 Model이라는 두 개의 객체만 추적하면 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wT3p5GO3G14L"
   },
   "outputs": [],
   "source": [
    "from transformers import WhisperProcessor\n",
    "\n",
    "processor = WhisperProcessor.from_pretrained(model_id, language=\"Korean\", task=\"transcribe\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GYvRvgvxG6Sx"
   },
   "source": [
    "### Prepare Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mVvcgSQCI8qW"
   },
   "source": [
    "보유한 음성 데이터와 이에 매치되는 텍스트 전사 데이터를 모델에 입력할 수 있는 형태로 변환해야 한다. 앞서 언급했듯 WhisperFeatureExtractor는 16kHz의 오디오 데이터를 입력으로 받으므로 이에 맞추어 오디오 데이터를 리샘플링해야 한다.\n",
    "\n",
    "본 프로젝트에서는 AI-HUB의 '[저음질 전화 음성인식 데이터](https://www.aihub.or.kr/aihubdata/data/view.do?currMenu=115&topMenu=100&dataSetSn=571)'의 일부를 활용한다. 이 데이터셋은 각 문장별로 음성 데이터(wav 파일)와 해당 음성 데이터의 전사 데이터(text 파일)이 같은 파일명으로 매치되어 있으며, labeled data의 경우 해당 통화 내용의 전체 텍스트가 정리된 json 파일이 1개씩 포함되어 있다. 자세한 사항은 링크를 통해 확인하자.\n",
    "\n",
    "이 데이터에 대하여 수행해야 할 전처리를 단계별로 구분하면 다음과 같다.\n",
    "\n",
    "1. 'idx, 오디오 파일 경로, transcription' 순으로 하나의 인스턴스가 만들어지도록 drive 내 파일들을 취합하여 DataFrame으로 만든다.\n",
    "2. 오디오 파일 경로를 이용해 sampling rate를 확인하고, 필요할 경우 16kHz로 리샘플링한다.\n",
    "3. 상기의 DataFrame을 input(오디오 경로)과 label(transcription)로 분류하여 x, y 데이터로 분할한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oqmQTFsuV8qA"
   },
   "source": [
    "#### 파일 경로 취합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "izh5If2Xq875"
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "# .wav와 .wavp 파일을 모두 취합\n",
    "path_wav = \"/kaggle/input/train-wav/AI스피커/*.wav\"\n",
    "\n",
    "# 두 경로에 맞는 파일 리스트를 합침\n",
    "raw_data_list = glob.glob(path_wav)\n",
    "\n",
    "# 정렬\n",
    "raw_data_list = sorted(raw_data_list)\n",
    "\n",
    "# 결과 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a8hl9gyquKvi"
   },
   "outputs": [],
   "source": [
    "print(f\"file_list : {raw_data_list[:10]}\")\n",
    "print(len(raw_data_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iN8xV58rv8Gt"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# 2. 텍스트 파일 경로 취합\n",
    "path = \"/kaggle/input/train-wav/train_output.csv\"\n",
    "df = pd.read_csv(path)\n",
    "df = df[df['label']=='[라벨]4.AI스피커']\n",
    "# 레이블 데이터에는 json 데이터가 폴더별로 하나씩 있으므로 txt 파일만을 골라낸다.\n",
    "# labeled_data_list = sorted([file for file in labeled_data_list if file.endswith(\".txt\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xVm31tbEwCkQ"
   },
   "outputs": [],
   "source": [
    "display(df[:10])\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8yzExkfr1m3K"
   },
   "source": [
    "> 텍스트 데이터는 파일의 내용을 추출하여 데이터프레임으로 만든다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vMWg4EJnRSGh"
   },
   "outputs": [],
   "source": [
    "# 텍스트 데이터로 만든 데이터프레임에 음성 파일 경로 컬럼을 추가\n",
    "df[\"raw_data\"] = raw_data_list\n",
    "df = df.rename(columns={'stt_text':'transcript'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# # audio_file과 raw_data에서 파일 이름만 추출하여 비교\n",
    "df['raw_filename'] = df['raw_data'].apply(lambda x: os.path.basename(x))\n",
    "df['match'] = df['audio_file'] == df['raw_filename']\n",
    "\n",
    "# 결과 출력\n",
    "print(df[['audio_file', 'raw_data', 'match']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['match']==False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "raw_file_names = [os.path.basename(path) for path in raw_data_list]\n",
    "raw_data_df = pd.DataFrame({'audio_file': raw_file_names})\n",
    "missing_files = df[~df['audio_file'].isin(raw_data_df['audio_file'])]\n",
    "missing_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vB-id8psrzC6"
   },
   "outputs": [],
   "source": [
    "# 필요에 따라 데이터프레임을 csv 파일로 저장한다.\n",
    "df.to_csv(\"transcript.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S8ZA01YIW-2a"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# csv 파일을 로드하여 df로 변환\n",
    "df = pd.read_csv(\"transcript.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3zXGWsIiXjG7",
    "outputId": "5a7dc3b6-2a63-46c2-eccb-09ecb39da50d"
   },
   "outputs": [],
   "source": [
    "# Null data 유무 확인\n",
    "df.isnull().values.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6hTUwjCDAw6K"
   },
   "source": [
    "#### Transformer Dataset 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2vCVgBuQj7QB"
   },
   "source": [
    "취합한 데이터프레임을 Transformers의 DatasetDict로 만들어 두면 해당 데이터를 언제 어디서든 자유롭게 활용할 수 있다. 물론 컴퓨팅 환경이 적합하다면 오프라인이 훨씬 빠르겠지만, 그렇지 않다면 고려해볼 수 있는 사항이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UWz8v1DRAxA1"
   },
   "outputs": [],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "from datasets import Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "reyQMzWDAxFy"
   },
   "outputs": [],
   "source": [
    "# 오디오 파일 경로를 dict의 \"audio\" 키의 value로 넣고 이를 데이터셋으로 변환\n",
    "# 이때, Whisper가 요구하는 사양대로 Sampling rate는 16,000으로 설정한다.\n",
    "ds = Dataset.from_dict({\"audio\": [path for path in df[\"raw_data\"]],\n",
    "                       \"transcripts\": [transcript for transcript in df[\"transcript\"]]}).cast_column(\"audio\", Audio(sampling_rate=16000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds = Dataset.from_dict({\n",
    "#     \"audio\": [{\"path\": path, \"sampling_rate\": 16000} for path in df[\"raw_data\"]],\n",
    "#     \"transcripts\": [transcript for transcript in df[\"transcript\"]]\n",
    "# })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def prepare_dataset(example):\n",
    "#     # audio 딕셔너리에서 'array' 키를 제거\n",
    "#     audio_info = {\n",
    "#         'path': example['audio']['path'],\n",
    "#         'sampling_rate': example['audio']['sampling_rate']\n",
    "#     }\n",
    "    \n",
    "#     return {\n",
    "#         'audio': audio_info,\n",
    "#         'transcripts': example['transcripts']\n",
    "#     }\n",
    "\n",
    "# # 데이터셋에 prepare_dataset 함수 적용\n",
    "# ds = ds.map(prepare_dataset)\n",
    "\n",
    "# # 결과 확인\n",
    "# print(ds[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UM22hDAuBEBe"
   },
   "outputs": [],
   "source": [
    "# 데이터셋을 훈련 데이터와 테스트 데이터, 밸리데이션 데이터로 분할\n",
    "train_testvalid = ds.train_test_split(test_size=0.1)\n",
    "# test_valid = train_testvalid[\"test\"].train_test_split(test_size=0.5)\n",
    "datasets = DatasetDict({\n",
    "    \"train\": train_testvalid[\"train\"],\n",
    "#     \"test\": test_valid[\"test\"],\n",
    "    \"valid\": train_testvalid[\"test\"]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets['train'][0]['audio']['array'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NTSv8hVyuPXg"
   },
   "outputs": [],
   "source": [
    "# # # 작성한 데이터셋을 허깅페이스에 업로드\n",
    "# datasets.push_to_hub(\"Old_People_Talk_Dataset_Ko\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ex6n0rsO8H9K"
   },
   "source": [
    "### Dataset Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eaFdLNCpLTZi"
   },
   "source": [
    "> 업로드된 데이터셋을 다운로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iEFp456gM0La"
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81,
     "referenced_widgets": [
      "a322ed63f08c46f89b4124015dad2dee",
      "98ed4d592243454c8042eab083a39e3e",
      "489b096c408e40c0976f721ce0c62e97",
      "1bbb81bcb7d245c69b2b6f0e3ab89c17",
      "0a3572276cea4178b6ab0a4e4ed88ac8",
      "e8f2bfdd19bc46c080f9a25402f6bf3f",
      "9b9e5ee571d041df967a101b7800e63b",
      "1e0aac59c0934ede94866122ac286dd8",
      "6373950f756442ce8bf3b26a0dfe2123",
      "130096de625f40c396baf75240c7fc6d",
      "90d8c20bec074f248b09ed3b692c1291",
      "7032cb1597454597804b8e9f28931f7c",
      "8787afb57a9f4e7d91d541218325b834",
      "06118ae5dcb74f63be1f78c1a02c5be3",
      "5c70a19c1dcb4eb6a78ebe1cbfbd0545",
      "3f4ee8d0c65b4d0cbc726be453f73f7a",
      "cdf70e19ff0b46a785bd8f50589470dc",
      "858edb61e4ed4370adb7f1442ecbdb82",
      "ace29a2e5ed0451ab1916e24aee77c60",
      "5d36fac565c04cb8bdf34ba07ece9545",
      "300747c4a81d461aae4d9d921256812d",
      "0316ed929fe74c749efae67f3c83df06"
     ]
    },
    "id": "xzqA1-lMuP_I",
    "outputId": "a83b7c74-a090-44a8-f1a0-f1518c2d17b4"
   },
   "outputs": [],
   "source": [
    "# # 데이터셋을 업로드할 때 접근을 제한하거나 비공개로 설정한 경우 허깅페이스 로그인이 필요하다.\n",
    "# datasets  = load_dataset(\"sikaro/Old_People_Talk_Dataset_Ko\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lE5ggVuWx0qp"
   },
   "source": [
    "데이터셋에 대하여 다음의 작업을 수행할 함수를 선언한다.\n",
    "1. 오디오 데이터를 로드하고 리샘플링을 실시\n",
    "2. feature extractor를 통해 1차원 오디오 배열을 log-Mel spectrogram으로 변환\n",
    "3. tokenizer를 이용해 전사 데이터를 label ids로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S8sx6sS-vRPY"
   },
   "outputs": [],
   "source": [
    "from scipy.io.wavfile import read\n",
    "import numpy as np\n",
    "\n",
    "def prepare_dataset(batch):\n",
    "    # 오디오 파일을 16kHz로 로드\n",
    "    audio = batch[\"audio\"]\n",
    "#     _, data = read(audio)\n",
    "#     audio_array = np.array(data, dtype=np.float32)\n",
    "    # input audio array로부터 log-Mel spectrogram 변환\n",
    "    batch[\"input_features\"] = feature_extractor(audio['array'], sampling_rate=audio[\"sampling_rate\"]).input_features[0]\n",
    "    # target text를 label ids로 변환\n",
    "    batch[\"labels\"] = tokenizer(batch[\"transcripts\"]).input_ids\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import math\n",
    "# from datasets import concatenate_datasets\n",
    "\n",
    "# # 저장소 이름 설정\n",
    "# repo_name = \"Old_People_Talk_Dataset_Ko\"\n",
    "\n",
    "# # 청크 크기와 총 청크 수 계산\n",
    "# chunk_size = 10000  # 메모리 사용량에 따라 조정\n",
    "# total_samples = len(datasets['train'])\n",
    "# num_chunks = math.ceil(total_samples / chunk_size)\n",
    "\n",
    "# processed_chunks = []\n",
    "\n",
    "# # 처리할 데이터셋 리스트\n",
    "# splits = ['train', 'valid', 'test']\n",
    "\n",
    "# for split in splits:\n",
    "#     print(f\"Processing {split} dataset\")\n",
    "#     total_samples = len(datasets[split])\n",
    "#     num_chunks = math.ceil(total_samples / chunk_size)\n",
    "    \n",
    "#     processed_chunks = []\n",
    "\n",
    "#     for i in range(num_chunks):\n",
    "#         print(f\"Processing chunk {i+1}/{num_chunks} of {split}\")\n",
    "#         start_idx = i * chunk_size\n",
    "#         end_idx = min((i + 1) * chunk_size, total_samples)\n",
    "        \n",
    "#         chunk = datasets[split].select(range(start_idx, end_idx))\n",
    "#         processed_chunk = chunk.map(prepare_dataset, remove_columns=chunk.column_names, num_proc=None)\n",
    "#         processed_chunks.append(processed_chunk)\n",
    "        \n",
    "#         if (i + 1) % 5 == 0 or i == num_chunks - 1:\n",
    "#             combined_chunk = concatenate_datasets(processed_chunks)\n",
    "#             repo_name_split = f\"{repo_name}_{split}\"\n",
    "#             combined_chunk.push_to_hub(repo_name_split, private=True)\n",
    "#             processed_chunks = []\n",
    "#             print(f\"Uploaded {split} chunks {i-3} to {i+1} to {repo_name_split}\")\n",
    "\n",
    "\n",
    "# print(\"All parts have been processed and uploaded successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aQYcqdDqvRT4"
   },
   "outputs": [],
   "source": [
    "# # 데이터 전처리 함수를 데이터셋 전체에 적용\n",
    "low_call_voices = datasets.map(prepare_dataset, remove_columns=datasets.column_names[\"train\"], num_proc=None)\n",
    "# # 데이터 전처리 함수를 데이터셋 전체에 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_call_voices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# low_call_voices_test = datasets.map(prepare_dataset, remove_columns=datasets.column_names[\"test\"], num_proc=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# low_call_voices_valid = datasets.map(prepare_dataset, remove_columns=datasets.column_names[\"valid\"], num_proc=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from datasets import DatasetDict\n",
    "\n",
    "# # 각각의 데이터셋을 하나의 DatasetDict로 묶기\n",
    "# combined_dataset = DatasetDict({\n",
    "#     'train': low_call_voices,\n",
    "# #     'test': low_call_voices_test,\n",
    "#     'valid': low_call_voices_valid\n",
    "# })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "72zMpmv2Moge"
   },
   "outputs": [],
   "source": [
    "# 전처리 작업이 오래 걸릴 수 있으므로, colab을 사용하여 파인튜닝을 진행한다면 전처리가 완료된 데이터셋을 Hub에 저장하는 것을 추천한다.\n",
    "low_call_voices.push_to_hub(\"Old_People_Talk_Dataset_Ko_Train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pDxREtX-mFnx"
   },
   "source": [
    "> 이 부분부터 런타임 유형을 GPU로 설정하는 것을 추천"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kxfcR80n8SwM"
   },
   "source": [
    "### Download preprocessed dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "fWMSgKLSJhGi"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d621efaf7cab41289702067d1edb01b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/223 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cbeed9abdbf42f0b2246eda3c76fd5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "367ca0f164b946d4b31d7b69a56bf87c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/223 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9803a85566f421cb45d59eea9c2e0c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ad77c99540a4d649f1394297b143e81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset shards:   0%|          | 0/223 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fc752f4b8bc423abfbcb819cb393750",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset shards:   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_features', 'labels'],\n",
       "        num_rows: 72286\n",
       "    })\n",
       "    valid: Dataset({\n",
       "        features: ['input_features', 'labels'],\n",
       "        num_rows: 8032\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hub로부터 전처리가 완료된 데이터셋을 로드\n",
    "from datasets import load_dataset\n",
    "low_call_voices_prepreocessed = load_dataset(\"sikaro/Old_People_Talk_Dataset_Ko_Train\")\n",
    "low_call_voices_prepreocessed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r5FwPUUaO350"
   },
   "source": [
    "### Prepare Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pP0Te5S4O39c"
   },
   "source": [
    "이제 데이터가 준비되었으므로 training pipeline을 수행할 준비가 되었다. Hugging face의 'Trainer'를 사용하면 다음의 단계에 따라 간단히 수행할 수 있다.\n",
    "\n",
    "1. data collator 선언 : data collator는 우리가 전처리한 데이터를 받아 모델에 입력할 수 있는 PyTorch Tensor 형태로 변환해준다.\n",
    "2. 평가 지표 : 모델을 평가하기 위한 지표를 설정한다. 영어의 경우 Word Error Rate(WER)를 주로 사용하지만, 교착어인 한국어는 CER(Charactor Error Rate)를 사용하는 편이 더 효과적이다.\n",
    "3. pre-trained model checkpoint 로드 : pre-trained model checkpoint를 로드하고 학습을 위한 설정을 진행한다.\n",
    "4. Training argument의 정의 : Trainer가 활용할 수 있도록 argument를 설정한다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8JkuNu5dO4A8"
   },
   "source": [
    "#### Define a Data Collator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "paa5zHbWO4EU"
   },
   "source": [
    "Sequence-to-sequence 발화 모델을 위한 Data collator는 input_feature와 label을 독립적으로 다룬다는 점에서 독특한 성격을 보인다. input_feature는 feature extractor로, label은 tokenizer로 다루어야 한다.\n",
    "\n",
    "input_feature는 30초 길이로 패딩되고 고정된 차원의 log_mel spectrogram으로 변환되었으므로, 우리가 할 일은 이를 PyTorch tensor로 변환하는 것뿐이다. 이를 위해 .pad 메서드의 return_tensor=pt 인자를 사용한다. 이때 이미 패딩이 완료되었으므로 여기서 추가적인 패딩 작업이 이루어지지는 않으며, 그저 input_feature를 PyTorch tensor로 변환하기만 할 것이다.\n",
    "\n",
    "반면, label은 아직 패딩 작업이 이루어지지 않았다. 따라서 먼저 tokenizer의 .pad 메서드를 이용해 패딩 작업을 실시할 것이다. 패딩 토큰들은 -100으로 치환되며, 따라서 이 토큰들은 모델이 loss를 계산할 때는 이용되지 않을 것이다. 그리고 이후 training 작업 동안 우리는 label sequence의 시작 부분에 있는 transcript 토큰을 잘라낼 것이다.\n",
    "\n",
    "앞서 선언했던 WhisperPrecessor를 이용해 feature extractor와 tokenizer 모두를 사용할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "htpGKDwKO4IH"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from dataclasses import dataclass\n",
    "from typing import Any, Dict, List, Union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "ET9AfiDXSby3"
   },
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class DataCollatorSpeechSeq2SeqWithPadding:\n",
    "    processor: Any\n",
    "\n",
    "    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n",
    "        # 인풋 데이터와 라벨 데이터의 길이가 다르며, 따라서 서로 다른 패딩 방법이 적용되어야 한다. 그러므로 두 데이터를 분리해야 한다.\n",
    "        # 먼저 오디오 인풋 데이터를 간단히 토치 텐서로 반환하는 작업을 수행한다.\n",
    "        input_features = [{\"input_features\": feature[\"input_features\"]} for feature in features]\n",
    "        batch = self.processor.feature_extractor.pad(input_features, return_tensors=\"pt\")\n",
    "\n",
    "        # Tokenize된 레이블 시퀀스를 가져온다.\n",
    "        label_features = [{\"input_ids\": feature[\"labels\"]} for feature in features]\n",
    "        # 레이블 시퀀스에 대해 최대 길이만큼 패딩 작업을 실시한다.\n",
    "        labels_batch = self.processor.tokenizer.pad(label_features, return_tensors=\"pt\")\n",
    "\n",
    "        # 패딩 토큰을 -100으로 치환하여 loss 계산 과정에서 무시되도록 한다.\n",
    "        labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), -100)\n",
    "\n",
    "        # 이전 토크나이즈 과정에서 bos 토큰이 추가되었다면 bos 토큰을 잘라낸다.\n",
    "        # 해당 토큰은 이후 언제든 추가할 수 있다.\n",
    "        if (labels[:, 0] == self.processor.tokenizer.bos_token_id).all().cpu().item():\n",
    "            labels = labels[:, 1:]\n",
    "\n",
    "        batch[\"labels\"] = labels\n",
    "        batch[\"attention_mask\"] = labels_batch[\"attention_mask\"]\n",
    "        \n",
    "        return batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "6WMQm08gvPn5",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 훈련시킬 모델의 processor, tokenizer, feature extractor 로드\n",
    "from transformers import WhisperTokenizer,  WhisperFeatureExtractor\n",
    "from transformers import WhisperProcessor\n",
    "\n",
    "model_id = \"openai/whisper-large-v3\"\n",
    "processor = WhisperProcessor.from_pretrained(model_id, language=\"Korean\", task=\"transcribe\")\n",
    "tokenizer = WhisperTokenizer.from_pretrained(model_id, language=\"Korean\", task=\"transcribe\")\n",
    "feature_extractor = WhisperFeatureExtractor.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:                 저는 서울중앙지검 지능범죄수사팀 최인호 검사입니다.\n",
      "Decoded w/ special:    <|startoftranscript|><|ko|><|transcribe|><|notimestamps|>저는 서울중앙지검 지능범죄수사팀 최인호 검사입니다.<|endoftext|>\n",
      "Decoded w/out special: 저는 서울중앙지검 지능범죄수사팀 최인호 검사입니다.\n",
      "Are equal:             True\n"
     ]
    }
   ],
   "source": [
    "input_str = \"저는 서울중앙지검 지능범죄수사팀 최인호 검사입니다.\"\n",
    "labels = tokenizer(input_str).input_ids\n",
    "decoded_with_special = tokenizer.decode(labels, skip_special_tokens=False)\n",
    "decoded_str = tokenizer.decode(labels, skip_special_tokens=True)\n",
    "\n",
    "print(f\"Input:                 {input_str}\")\n",
    "print(f\"Decoded w/ special:    {decoded_with_special}\")\n",
    "print(f\"Decoded w/out special: {decoded_str}\")\n",
    "print(f\"Are equal:             {input_str == decoded_str}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "TVL8hh4ASb3A"
   },
   "outputs": [],
   "source": [
    "# 데이터 콜레이터 초기화\n",
    "data_collator = DataCollatorSpeechSeq2SeqWithPadding(processor=processor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bB2QxtWRSb6w"
   },
   "source": [
    "#### Evaluation Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TOWdI09I4DDx"
   },
   "source": [
    "검증 데이터셋에 사용할 evaluation metrics를 정의한다. 영어의 경우 WER을 사용하지만, 한국어 데이터이므로 CER을 사용하는 것이 더 적절할 것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "Z3mm-1MU4YU5"
   },
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "metric = evaluate.load('cer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BkCZBFpJ4dcU"
   },
   "source": [
    "이제 모델의 예측에 대해 CER metric을 반환할 함수를 선언한다.\n",
    "\n",
    "compute_metrics라는 이름의 이 함수는 가장 먼저 label_ids에 있는 -100을 pad_token으로 치환한다(data collator가 비용함수를 계산할 때 pad token을 무시하도록 하기 위해 설정한). 그 뒤 예측치와 label ids를 문자열로 변환하고 예측치와 정답을 비교하여 CER을 계산해낸다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "l5cOUbjCBr-U"
   },
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    pred_ids = pred.predictions\n",
    "    label_ids = pred.label_ids\n",
    "\n",
    "    # pad_token을 -100으로 치환\n",
    "    label_ids[label_ids == -100] = tokenizer.pad_token_id\n",
    "\n",
    "    # metrics 계산 시 special token들을 빼고 계산하도록 설정\n",
    "    pred_str = tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n",
    "    label_str = tokenizer.batch_decode(label_ids, skip_special_tokens=True)\n",
    "\n",
    "    cer = 100 * metric.compute(predictions=pred_str, references=label_str)\n",
    "\n",
    "    return {\"cer\": cer}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rHke2aFwDjW4"
   },
   "source": [
    "### Load a Pre-Trained Checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dZK9NMvaDxJ3"
   },
   "source": [
    "pre-trained Whisper base 모델의 checkpoint를 로드한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "ZCB8FICoDkX4"
   },
   "outputs": [],
   "source": [
    "from transformers import WhisperForConditionalGeneration\n",
    "\n",
    "model = WhisperForConditionalGeneration.from_pretrained(model_id,device_map=\"auto\",\n",
    "                                                       max_memory={0: \"6GiB\",1: \"16GiB\",2: \"16GiB\"},use_cache=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ExZZQm-KD2xH"
   },
   "source": [
    "Whisper 모델은 문장의 자동 생성이 시작되기 전 모델의 출력으로 강제되는 토큰(forced_decoder_ids)이 있다. 이 token ids는 전사 언어와 zero-shot ASR 작업에 영향을 미친다. 파인 튜닝을 위해 우리는 이 ids를 None으로 바꿔주어야 한다. 우리는 모델이 정확한 언어(한국어)로 예측하고 전사하도록 훈련할 것이기 때문이다.\n",
    "\n",
    "또한 문장의 생성 중 완전하게 억제되는 토큰들도 있다(suppress_tokens). 이 토큰들은 로그 확률을 -inf로 설정하며, 따라서 샘플링되지 않는다. 우리는 이 토큰들을 비어 있는 리스트로 치환할 것이다. 즉, 어떤 토큰도 억제되지 않는다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "prZpvNaoHxQy"
   },
   "outputs": [],
   "source": [
    "model.config.suppress_tokens = []\n",
    "model.generation_config.suppress_tokens = []\n",
    "\n",
    "model.config.forced_decoder_ids = processor.tokenizer.get_decoder_prompt_ids(\n",
    "            language='Korean',\n",
    "            task='transcribe',\n",
    "        )\n",
    "model.generation_config.forced_decoder_ids = processor.tokenizer.get_decoder_prompt_ids(\n",
    "            language='Korean',\n",
    "            task='transcribe',\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ksdUBfGzHxvp"
   },
   "source": [
    "### Define the Training Arguments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PO9WXLB3H0RT"
   },
   "source": [
    "마지막 단계로서, 트레이닝을 위한 모든 파라미터들을 정의해야 한다. 각각의 파라미터들은 다음과 같은 의미를 갖는다.\n",
    "\n",
    "- output_dir : 모델의 가중치를 저장하기 위한 경로를 설정한다. 이 경로는 허깅 페이스 허브의 리포지토리 이름으로도 설정 가능하다.\n",
    "- generation_max_length : 평가 작업 동안 자기회귀적으로 생성되는 토큰들의 최대 길이를 설정한다.\n",
    "- save_steps : 훈련 동안, 이 파라미터에 설정한 step마다 중간 체크포인트가 비동기적으로 저장 및 업로드될 것이다.\n",
    "- eval_steps : 훈련 동안, 이 파라미터에 설정한 step마다 체크포인트에 대한 평가가 이루어질 것이다.\n",
    "- report_to : 훈련 로그를 어디에 저장할지를 설정한다. 'azure_ml', 'comet_ml', 'mlflow', 'neptune', 'tensorboard' 그리고 'wandb'를 지원하며, 기본값은 'tensorboard'이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "qeFBglE4JUyP"
   },
   "outputs": [],
   "source": [
    "from transformers import Seq2SeqTrainingArguments\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"repo_name\",  # 원하는 리포지토리 이름을 임력한다.\n",
    "    per_device_train_batch_size=16,\n",
    "    gradient_accumulation_steps=1,  # 배치 크기가 2배 감소할 때마다 2배씩 증가\n",
    "    learning_rate=1e-5,\n",
    "    warmup_steps=50,\n",
    "    max_steps=600,  # epoch 대신 설정\n",
    "    gradient_checkpointing=True,\n",
    "    fp16=True,\n",
    "    eval_strategy=\"steps\",\n",
    "    per_device_eval_batch_size=8,\n",
    "    predict_with_generate=True,\n",
    "    generation_max_length=225,\n",
    "    save_steps=100,\n",
    "    eval_steps=100,\n",
    "    logging_steps=25,\n",
    "    report_to=[\"wandb\"],\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"cer\",  # 한국어의 경우 'wer'보다는 'cer'이 더 적합할 것\n",
    "    greater_is_better=False,\n",
    "    push_to_hub=True,\n",
    "    dataloader_num_workers=8,  # num_workers 설정\n",
    "    early_stopping_patience=1,  # 3번 연속 성능이 개선되지 않으면 멈춤\n",
    "    early_stopping_threshold=0.01  # 개선이 최소 1% 이상일 때만 학습 지속\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tHxTOlpdJ6UG"
   },
   "source": [
    "트레이닝 파라미터들의 설정이 끝났다면 트레이너를 설정한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.amp import GradScaler\n",
    "scaler = GradScaler('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_valid_split = low_call_voices_prepreocessed[\"valid\"].train_test_split(test_size=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "jikyDBQyMAvw"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/accelerate/accelerator.py:494: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n",
      "max_steps is given, it will override any value given in num_train_epochs\n"
     ]
    }
   ],
   "source": [
    "from transformers import Seq2SeqTrainer\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    args=training_args,\n",
    "    model=model,\n",
    "    train_dataset=low_call_voices_prepreocessed['train'],\n",
    "    eval_dataset=train_valid_split['test'],  # or \"test\"\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=processor.feature_extractor,\n",
    "   \n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iw-Cg2DlTngN"
   },
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "dxUVJ24kTpQ6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbellkjtt\u001b[0m (\u001b[33msikaro\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/root/wandb/run-20241001_100417-mtqkwz73</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sikaro/huggingface/runs/mtqkwz73' target=\"_blank\">repo_name</a></strong> to <a href='https://wandb.ai/sikaro/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sikaro/huggingface' target=\"_blank\">https://wandb.ai/sikaro/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sikaro/huggingface/runs/mtqkwz73' target=\"_blank\">https://wandb.ai/sikaro/huggingface/runs/mtqkwz73</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='600' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [600/600 2:30:28, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Cer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.336900</td>\n",
       "      <td>0.280254</td>\n",
       "      <td>7.376047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.167100</td>\n",
       "      <td>0.168833</td>\n",
       "      <td>5.193785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.126800</td>\n",
       "      <td>0.135755</td>\n",
       "      <td>5.988128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.128800</td>\n",
       "      <td>0.122376</td>\n",
       "      <td>6.101606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.095100</td>\n",
       "      <td>0.110647</td>\n",
       "      <td>6.380936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.102600</td>\n",
       "      <td>0.105363</td>\n",
       "      <td>7.349860</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/transformers/modeling_utils.py:2634: UserWarning: Moving the following attributes in the config to the generation config: {'max_length': 448, 'suppress_tokens': [], 'begin_suppress_tokens': [220, 50257]}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "There were missing keys in the checkpoint model loaded: ['proj_out.weight'].\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=600, training_loss=0.2764320723215739, metrics={'train_runtime': 9043.6486, 'train_samples_per_second': 1.062, 'train_steps_per_second': 0.066, 'total_flos': 3.2615983742976e+19, 'train_loss': 0.2764320723215739, 'epoch': 0.13280212483399734})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1uk_zS3GlMYM"
   },
   "source": [
    "#### Model uploading to HuggingFace hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "VAqfkEqqnd0o"
   },
   "outputs": [],
   "source": [
    "kwargs = {\n",
    "    \"dataset_tags\": \"sikaro/Old_People_Talk_Dataset_Ko_Train\",\n",
    "    \"dataset\": \"Old_People_Talk_Dataset_Ko_Train\",  # a 'pretty' name for the training dataset\n",
    "    \"dataset_args\": \"config: ko, split: valid\",\n",
    "    \"language\": \"ko\",\n",
    "    \"model_name\": \"Whisper_Old_People_Talk\",  # a 'pretty' name for your model\n",
    "    \"finetuned_from\": \"openai/whisper-large-v3\",\n",
    "    \"tasks\": \"automatic-speech-recognition\",\n",
    "    \"tags\": \"hf-asr-leaderboard\",\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "plO3hxasvgN0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/sikaro/repo_name/commit/e8abc874c611238829202aa38c8e3dc3da21c3b2', commit_message='End of training', commit_description='', oid='e8abc874c611238829202aa38c8e3dc3da21c3b2', pr_url=None, repo_url=RepoUrl('https://huggingface.co/sikaro/repo_name', endpoint='https://huggingface.co', repo_type='model', repo_id='sikaro/repo_name'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.push_to_hub(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "pXeaATSouf7a"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e16f1f57a3c4584b4eaf9fde05399ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/1.89k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fb31f77da344e53bda90d07ac09307b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/1.89k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No files have been modified since last commit. Skipping to prevent empty commit.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/sikaro/repo_name/commit/a2ce1da13a977deb263e5fcc36958a46f8bb363e', commit_message='Upload tokenizer', commit_description='', oid='a2ce1da13a977deb263e5fcc36958a46f8bb363e', pr_url=None, repo_url=RepoUrl('https://huggingface.co/sikaro/repo_name', endpoint='https://huggingface.co', repo_type='model', repo_id='sikaro/repo_name'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processor.push_to_hub(\"sikaro/repo_name\")\n",
    "tokenizer.push_to_hub(\"sikaro/repo_name\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zXLPziQSCrkL"
   },
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x2lMqjoGCu6q"
   },
   "source": [
    "#### Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TtFj5whGCrrw"
   },
   "outputs": [],
   "source": [
    "# 파인 튜닝한 모델을 로드\n",
    "from transformers import WhisperForConditionalGeneration, WhisperProcessor, WhisperFeatureExtractor, WhisperTokenizer\n",
    "\n",
    "model = WhisperForConditionalGeneration.from_pretrained(\"허브에 업로드한 모델 주소 입력\")\n",
    "\n",
    "feature_extractor = WhisperFeatureExtractor.from_pretrained(\"허브에 업로드한 모델 주소 입력\")\n",
    "tokenizer = WhisperTokenizer.from_pretrained(\"허브에 업로드한 모델 주소 입력\", language=\"Korean\", task=\"transcribe\")\n",
    "processor = WhisperProcessor.from_pretrained(\"허브에 업로드한 모델 주소 입력\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iZCIf8fJCyPq"
   },
   "source": [
    "#### Training argument 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jLSCkblzDArz"
   },
   "outputs": [],
   "source": [
    "from transformers import Seq2SeqTrainingArguments\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"repo_name\",  # 원하는 리포지토리 이름을 임력한다.\n",
    "    per_device_train_batch_size=16,\n",
    "    gradient_accumulation_steps=1,  # 배치 크기가 2배 감소할 때마다 2배씩 증가\n",
    "    learning_rate=1e-5,\n",
    "    warmup_steps=500,\n",
    "    max_steps=4000,\n",
    "    gradient_checkpointing=True,\n",
    "    fp16=True,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    per_device_eval_batch_size=8,\n",
    "    predict_with_generate=True,\n",
    "    generation_max_length=225,\n",
    "    save_steps=1000,\n",
    "    eval_steps=1000,\n",
    "    logging_steps=25,\n",
    "    report_to=[\"tensorboard\"],\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"cer\",  # 한국어의 경우 'wer'보다는 'cer'이 더 적합할 것\n",
    "    greater_is_better=False,\n",
    "    push_to_hub=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F_YHiWArDAut"
   },
   "outputs": [],
   "source": [
    "from transformers import Seq2SeqTrainer\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    args=training_args,\n",
    "    model=model,\n",
    "    train_dataset=low_call_voices_prepreocessed[\"train\"],\n",
    "    eval_dataset=low_call_voices_prepreocessed[\"test\"],  # for evaluation(not validation)\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=processor.feature_extractor,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VY5Myn9vDLwn"
   },
   "source": [
    "> Evaluation 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lUp3xrdNDAxq"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5' max='101' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  5/101 00:45 < 18:21, 0.09 it/s]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 30775,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0316ed929fe74c749efae67f3c83df06": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "057be99b849b4430b0b6ba9b5a78ffd0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "06118ae5dcb74f63be1f78c1a02c5be3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ace29a2e5ed0451ab1916e24aee77c60",
      "max": 19,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5d36fac565c04cb8bdf34ba07ece9545",
      "value": 19
     }
    },
    "0a3572276cea4178b6ab0a4e4ed88ac8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0e9568e0d7ca49eb85ab61b89c87d656": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "130096de625f40c396baf75240c7fc6d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "14381783c208488c8d164c57b9de05c1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1bbb81bcb7d245c69b2b6f0e3ab89c17": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_130096de625f40c396baf75240c7fc6d",
      "placeholder": "​",
      "style": "IPY_MODEL_90d8c20bec074f248b09ed3b692c1291",
      "value": " 19/19 [00:03&lt;00:00,  1.06it/s]"
     }
    },
    "1e0aac59c0934ede94866122ac286dd8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1f598dd5d3f14e58b71092bc28ce432a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2482321188ca4d7ea7d0aa05a55c6a17": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_579a883a320f41a7804aa962b5717184",
      "placeholder": "​",
      "style": "IPY_MODEL_8a7488b190d6481ab5da60b8dd1fa99f",
      "value": "Downloading (…)rocessor_config.json: 100%"
     }
    },
    "26a0737dbd0f4e429399f957d4992dd0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2de632dca3b54dd3804b8780ad47ae3c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "300747c4a81d461aae4d9d921256812d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "309079d9aa154d8293dbbb137992697c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "324ff2dfa9ab4f2fb190fd8faf98215e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "35869e945db945bcad9801f6951d0ebe": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_309079d9aa154d8293dbbb137992697c",
      "placeholder": "​",
      "style": "IPY_MODEL_45a0e90ec7154cd49b1284e05ce82a10",
      "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
     }
    },
    "3ee064066214437fbf83cddd2f2ece82": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "CheckboxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "CheckboxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "CheckboxView",
      "description": "Add token as git credential?",
      "description_tooltip": null,
      "disabled": false,
      "indent": true,
      "layout": "IPY_MODEL_f646d9d1833144ea89b756304e899af9",
      "style": "IPY_MODEL_92b0d6145d5d4c50acf0594c61d9474f",
      "value": true
     }
    },
    "3f20227729f640e18020f1c4cfefbf2d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3f4ee8d0c65b4d0cbc726be453f73f7a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "45a0e90ec7154cd49b1284e05ce82a10": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "46bec1bb11bb41d6817a3bdef7f3dbe8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "489b096c408e40c0976f721ce0c62e97": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1e0aac59c0934ede94866122ac286dd8",
      "max": 19,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6373950f756442ce8bf3b26a0dfe2123",
      "value": 19
     }
    },
    "4c3472eee03d44fb910edefc35ffa1dd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4dbda086cbac453893bf85da71c170e6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "555d32c5f0484445a5da8012b6462911": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": "center",
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "flex",
      "flex": null,
      "flex_flow": "column",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "50%"
     }
    },
    "579a883a320f41a7804aa962b5717184": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5c70a19c1dcb4eb6a78ebe1cbfbd0545": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_300747c4a81d461aae4d9d921256812d",
      "placeholder": "​",
      "style": "IPY_MODEL_0316ed929fe74c749efae67f3c83df06",
      "value": " 19/19 [00:00&lt;00:00, 1594.51it/s]"
     }
    },
    "5d36fac565c04cb8bdf34ba07ece9545": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "605675837ac54671ab0df785b058469a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9e0741d8616c458098712f14b126a579",
      "placeholder": "​",
      "style": "IPY_MODEL_f887cd43e1b646c99e9f659f55165594",
      "value": "Connecting..."
     }
    },
    "6373950f756442ce8bf3b26a0dfe2123": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "7032cb1597454597804b8e9f28931f7c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_8787afb57a9f4e7d91d541218325b834",
       "IPY_MODEL_06118ae5dcb74f63be1f78c1a02c5be3",
       "IPY_MODEL_5c70a19c1dcb4eb6a78ebe1cbfbd0545"
      ],
      "layout": "IPY_MODEL_3f4ee8d0c65b4d0cbc726be453f73f7a"
     }
    },
    "858edb61e4ed4370adb7f1442ecbdb82": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8787afb57a9f4e7d91d541218325b834": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cdf70e19ff0b46a785bd8f50589470dc",
      "placeholder": "​",
      "style": "IPY_MODEL_858edb61e4ed4370adb7f1442ecbdb82",
      "value": "Resolving data files: 100%"
     }
    },
    "89208f995baf43acb49a90411ceb50d2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8c98f4c838e34fe3b1fee4d0224ec777",
      "placeholder": "​",
      "style": "IPY_MODEL_a4d2300d505b4195bc453b69e6d68a7c",
      "value": " 185k/185k [00:00&lt;00:00, 507kB/s]"
     }
    },
    "8a666ca2a4864ba1887bd1b5804faa17": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "VBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_bd86225d9b5f4acdbd1e5f9eae9f85e3",
       "IPY_MODEL_fccc44d5467e4660927ad7a9bae4d889",
       "IPY_MODEL_cf070973ffb643a8a3d2ee30044bc87b",
       "IPY_MODEL_a33310753e834669bda1b10eafb7e006"
      ],
      "layout": "IPY_MODEL_555d32c5f0484445a5da8012b6462911"
     }
    },
    "8a7488b190d6481ab5da60b8dd1fa99f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8c98f4c838e34fe3b1fee4d0224ec777": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8cb41a204d3d4eeab683b0cf89301646": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "90d8c20bec074f248b09ed3b692c1291": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "92b0d6145d5d4c50acf0594c61d9474f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "98646532593b4d3aacdfbc5f7d76055a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "98ed4d592243454c8042eab083a39e3e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e8f2bfdd19bc46c080f9a25402f6bf3f",
      "placeholder": "​",
      "style": "IPY_MODEL_9b9e5ee571d041df967a101b7800e63b",
      "value": "Resolving data files: 100%"
     }
    },
    "9a2a439687a446e19a8be6643818acb4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ButtonStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ButtonStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "button_color": null,
      "font_weight": ""
     }
    },
    "9b9e5ee571d041df967a101b7800e63b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9e0741d8616c458098712f14b126a579": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a322ed63f08c46f89b4124015dad2dee": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_98ed4d592243454c8042eab083a39e3e",
       "IPY_MODEL_489b096c408e40c0976f721ce0c62e97",
       "IPY_MODEL_1bbb81bcb7d245c69b2b6f0e3ab89c17"
      ],
      "layout": "IPY_MODEL_0a3572276cea4178b6ab0a4e4ed88ac8"
     }
    },
    "a33310753e834669bda1b10eafb7e006": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_46bec1bb11bb41d6817a3bdef7f3dbe8",
      "placeholder": "​",
      "style": "IPY_MODEL_26a0737dbd0f4e429399f957d4992dd0",
      "value": "Login successful"
     }
    },
    "a4d2300d505b4195bc453b69e6d68a7c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ace29a2e5ed0451ab1916e24aee77c60": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ae6f53af1a594e639fb042b9d75761f2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ButtonModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ButtonModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ButtonView",
      "button_style": "",
      "description": "Login",
      "disabled": false,
      "icon": "",
      "layout": "IPY_MODEL_98646532593b4d3aacdfbc5f7d76055a",
      "style": "IPY_MODEL_9a2a439687a446e19a8be6643818acb4",
      "tooltip": ""
     }
    },
    "bd86225d9b5f4acdbd1e5f9eae9f85e3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_14381783c208488c8d164c57b9de05c1",
      "placeholder": "​",
      "style": "IPY_MODEL_8cb41a204d3d4eeab683b0cf89301646",
      "value": "Token is valid (permission: write)."
     }
    },
    "c0415d722c5f4315bf0f5a20c3adfe31": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_2482321188ca4d7ea7d0aa05a55c6a17",
       "IPY_MODEL_c704283085e843b1a60656aa93a3dc09",
       "IPY_MODEL_89208f995baf43acb49a90411ceb50d2"
      ],
      "layout": "IPY_MODEL_057be99b849b4430b0b6ba9b5a78ffd0"
     }
    },
    "c5d07d2ec47a42ff9b71be5a86357e5a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1f598dd5d3f14e58b71092bc28ce432a",
      "placeholder": "​",
      "style": "IPY_MODEL_4c3472eee03d44fb910edefc35ffa1dd",
      "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
     }
    },
    "c704283085e843b1a60656aa93a3dc09": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ee23f65322c5441a8bc3d119e2e59bfc",
      "max": 184990,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2de632dca3b54dd3804b8780ad47ae3c",
      "value": 184990
     }
    },
    "cdf70e19ff0b46a785bd8f50589470dc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cf070973ffb643a8a3d2ee30044bc87b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ea322a87eb3642b9a4f387f71fd9c548",
      "placeholder": "​",
      "style": "IPY_MODEL_324ff2dfa9ab4f2fb190fd8faf98215e",
      "value": "Your token has been saved to /root/.cache/huggingface/token"
     }
    },
    "e50f35331b3847fd96cc6d71fe9628b2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "PasswordModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "PasswordModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "PasswordView",
      "continuous_update": true,
      "description": "Token:",
      "description_tooltip": null,
      "disabled": false,
      "layout": "IPY_MODEL_0e9568e0d7ca49eb85ab61b89c87d656",
      "placeholder": "​",
      "style": "IPY_MODEL_4dbda086cbac453893bf85da71c170e6",
      "value": ""
     }
    },
    "e657defd8b9847f1a4b8294e5f43c972": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e8f2bfdd19bc46c080f9a25402f6bf3f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ea322a87eb3642b9a4f387f71fd9c548": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ee23f65322c5441a8bc3d119e2e59bfc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f646d9d1833144ea89b756304e899af9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f887cd43e1b646c99e9f659f55165594": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fccc44d5467e4660927ad7a9bae4d889": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e657defd8b9847f1a4b8294e5f43c972",
      "placeholder": "​",
      "style": "IPY_MODEL_3f20227729f640e18020f1c4cfefbf2d",
      "value": "Your token has been saved in your configured git credential helpers (store)."
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
